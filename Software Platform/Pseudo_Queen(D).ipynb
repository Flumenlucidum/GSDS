{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:43.948987Z",
     "start_time": "2018-11-27T12:20:30.225783Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('../midi')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:52.800756Z",
     "start_time": "2018-11-27T12:20:43.965495Z"
    }
   },
   "outputs": [],
   "source": [
    "from midi_utils import midiread, midiwrite\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.io as io\n",
    "from IPython.display import FileLink\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:52.867674Z",
     "start_time": "2018-11-27T12:20:52.819795Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "def midi_filename_to_piano_roll(midi_filename):\n",
    "    \n",
    "    midi_data = midiread(midi_filename, dt=0.3)\n",
    "    \n",
    "    piano_roll = midi_data.piano_roll.transpose()\n",
    "    \n",
    "    # Pressed notes are replaced by 1\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "    \n",
    "    return piano_roll\n",
    "\n",
    "\n",
    "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
    "        \n",
    "    original_piano_roll_length = piano_roll.shape[1]\n",
    "    \n",
    "    padded_piano_roll = np.zeros((88, max_length))\n",
    "    padded_piano_roll[:] = pad_value\n",
    "    \n",
    "    padded_piano_roll[:, -original_piano_roll_length:] = piano_roll\n",
    "\n",
    "    return padded_piano_roll\n",
    "\n",
    "\n",
    "class NotesGenerationDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
    "        \n",
    "        self.midi_folder_path = midi_folder_path\n",
    "        \n",
    "        midi_filenames = os.listdir(midi_folder_path)\n",
    "        \n",
    "        self.longest_sequence_length = longest_sequence_length\n",
    "        \n",
    "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n",
    "        \n",
    "        self.midi_full_filenames = list(midi_full_filenames)\n",
    "        \n",
    "        if longest_sequence_length is None:\n",
    "            \n",
    "            self.update_the_max_length()\n",
    "    \n",
    "    \n",
    "    def update_the_max_length(self):\n",
    "        \n",
    "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],self.midi_full_filenames)\n",
    "        \n",
    "        max_length = max(sequences_lengths)\n",
    "        \n",
    "        self.longest_sequence_length = max_length\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.midi_full_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        midi_full_filename = self.midi_full_filenames[index]\n",
    "        \n",
    "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
    "        \n",
    "        # Shifting by one time step\n",
    "        sequence_length = piano_roll.shape[1] - 1\n",
    "        \n",
    "        # Shifting by one time step\n",
    "        input_sequence = piano_roll[:, :-1]\n",
    "        ground_truth_sequence = piano_roll[:, 1:]\n",
    "                \n",
    "        # padding sequence so that all of them have the same length\n",
    "        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n",
    "        \n",
    "        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,max_length=self.longest_sequence_length,pad_value=-100)\n",
    "                \n",
    "        input_sequence_padded = input_sequence_padded.transpose()\n",
    "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
    "        \n",
    "        return (torch.FloatTensor(input_sequence_padded),torch.LongTensor(ground_truth_sequence_padded),torch.LongTensor([sequence_length]) )\n",
    "\n",
    "    \n",
    "def post_process_sequence_batch(batch_tuple):\n",
    "    \n",
    "    input_sequences, output_sequences, lengths = batch_tuple\n",
    "    \n",
    "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
    "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
    "    splitted_lengths_batch = lengths.split(split_size=1)\n",
    "\n",
    "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
    "                               splitted_output_sequence_batch,\n",
    "                               splitted_lengths_batch)\n",
    "\n",
    "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
    "                                         key=lambda p: int(p[2]),\n",
    "                                         reverse=True)\n",
    "\n",
    "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
    "\n",
    "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
    "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
    "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
    "    \n",
    "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
    "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
    "    \n",
    "    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
    "    \n",
    "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
    "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
    "    \n",
    "    return input_sequence_batch_transposed, output_sequence_batch_sorted, list(lengths_batch_sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_filename_to_piano_roll_code(midi_filename):\n",
    "    \n",
    "    midi_data = midiread(midi_filename, dt=0.3)\n",
    "    \n",
    "    \n",
    "    piano_roll = midi_data.piano_roll.transpose()\n",
    "    limit=piano_roll.shape[1]//4\n",
    "    for i in range(1,limit+1):\n",
    "    \n",
    "        b=np.sum(piano_roll[:,4*(i-1):4*i], axis=1)\n",
    "\n",
    "        d=np.where(b==np.amax(b))\n",
    "       \n",
    "        #piano_roll[:,4*(i-1):4*i]=0\n",
    "        piano_roll[d,4*(i-1):4*i]=1\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    b=np.sum(piano_roll[:,4*limit:], axis=1)\n",
    "\n",
    "    d=np.where(b==np.amax(b))\n",
    "    #piano_roll[:,4*limit:]=0\n",
    "    piano_roll[d,4*limit:]=1\n",
    "\n",
    "    # Pressed notes are replaced by 1\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "    \n",
    "    return piano_roll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=np.array([1,5,3,4,5])\n",
    "d=np.where(b==np.amax(b))\n",
    "np.repeat(5,len(d[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotesGenerationDataset_code(data.Dataset):\n",
    "    \n",
    "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
    "        \n",
    "        self.midi_folder_path = midi_folder_path\n",
    "        \n",
    "        midi_filenames = os.listdir(midi_folder_path)\n",
    "        \n",
    "        self.longest_sequence_length = longest_sequence_length\n",
    "        \n",
    "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n",
    "        \n",
    "        self.midi_full_filenames = list(midi_full_filenames)\n",
    "        \n",
    "        if longest_sequence_length is None:\n",
    "            \n",
    "            self.update_the_max_length()\n",
    "    \n",
    "    \n",
    "    def update_the_max_length(self):\n",
    "        \n",
    "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll_code(filename).shape[1],self.midi_full_filenames)\n",
    "        \n",
    "        max_length = max(sequences_lengths)\n",
    "        \n",
    "        self.longest_sequence_length = max_length\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.midi_full_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        midi_full_filename = self.midi_full_filenames[index]\n",
    "        \n",
    "        piano_roll = midi_filename_to_piano_roll_code(midi_full_filename)\n",
    "        \n",
    "        # Shifting by one time step\n",
    "        sequence_length = piano_roll.shape[1] - 1\n",
    "        \n",
    "        # Shifting by one time step\n",
    "        input_sequence = piano_roll[:, :-1]\n",
    "        ground_truth_sequence = piano_roll[:, 1:]\n",
    "                \n",
    "        # padding sequence so that all of them have the same length\n",
    "        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n",
    "        \n",
    "        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,max_length=self.longest_sequence_length,pad_value=-100)\n",
    "                \n",
    "        input_sequence_padded = input_sequence_padded.transpose()\n",
    "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
    "        \n",
    "        return (torch.FloatTensor(input_sequence_padded),torch.LongTensor(ground_truth_sequence_padded),torch.LongTensor([sequence_length]) )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('Pseudo_Queen'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob(os.path.join('./musictraining/Queen', '*.*')):\n",
    "    shutil.copy(filename, './Pseudo_Queen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_folder_path = './Pseudo_Queen'\n",
    "        \n",
    "midi_filenames = os.listdir(midi_folder_path)\n",
    "midi_full_filenames =map(lambda filename: os.path.join(midi_folder_path, filename), midi_filenames)\n",
    "\n",
    "for filename in list(midi_full_filenames):\n",
    "    \n",
    "    \n",
    "    try: sequences_lengths = midi_filename_to_piano_roll(filename).shape[1]\n",
    "    \n",
    "    except:\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)\n",
    "        elif os.path.isdir(filename):\n",
    "            shutil.rmtree(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:07.678124Z",
     "start_time": "2018-11-27T12:20:56.931002Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = NotesGenerationDataset('./Pseudo_Queen', longest_sequence_length=None)\n",
    "\n",
    "trainset_loader = data.DataLoader(trainset, batch_size=8,shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:08.232332Z",
     "start_time": "2018-11-27T12:21:07.693745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2772, 88])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = next(iter(trainset_loader))\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:11.258476Z",
     "start_time": "2018-11-27T12:21:08.259258Z"
    }
   },
   "outputs": [],
   "source": [
    "valset = NotesGenerationDataset_code('./Pseudo_Queen', longest_sequence_length=None)\n",
    "\n",
    "valset_loader = data.DataLoader(valset, batch_size=8, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:11.406325Z",
     "start_time": "2018-11-27T12:21:11.278687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2772, 88])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = next(iter(valset_loader))\n",
    "X_val[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:33.314323Z",
     "start_time": "2018-11-27T12:22:33.291386Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, n_layers=2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.notes_encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_sequences, input_sequences_lengths, hidden=None):\n",
    "        batch_size = input_sequences.shape[1]\n",
    "\n",
    "        notes_encoded = self.notes_encoder(input_sequences)\n",
    "        \n",
    "        notes_encoded_rolled = notes_encoded.permute(1,2,0).contiguous()\n",
    "        notes_encoded_norm = self.bn(notes_encoded_rolled)\n",
    "        \n",
    "        notes_encoded_norm_drop = nn.Dropout(0.25)(notes_encoded_norm)\n",
    "        notes_encoded_complete = notes_encoded_norm_drop.permute(2,0,1)\n",
    "        \n",
    "        # Here we run rnns only on non-padded regions of the batch\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(notes_encoded_complete, input_sequences_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        # Here we unpack sequence(back to padded)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        \n",
    "        outputs_norm = self.bn(outputs.permute(1,2,0).contiguous())\n",
    "        outputs_drop = nn.Dropout(0.1)(outputs_norm)\n",
    "        logits = self.logits_fc(outputs_drop.permute(2,0,1))\n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        \n",
    "        neg_logits = (1 - logits)\n",
    "        \n",
    "        # Since the BCE loss doesn't support masking,crossentropy is used\n",
    "        binary_logits = torch.stack((logits, neg_logits), dim=3).contiguous()\n",
    "        logits_flatten = binary_logits.view(-1, 2)\n",
    "        return logits_flatten, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:57.954631Z",
     "start_time": "2018-11-27T12:22:36.786295Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RNN(input_size=88, hidden_size=512, num_classes=88).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion_val = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:58.002722Z",
     "start_time": "2018-11-27T12:22:57.987764Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "    model.eval()\n",
    "    full_val_loss = 0.0\n",
    "    overall_sequence_length = 0.0\n",
    "\n",
    "    for batch in valset_loader:\n",
    "\n",
    "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "        logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "        loss = criterion_val(logits, output_sequences_batch_var)\n",
    "\n",
    "        full_val_loss += loss.item()\n",
    "        overall_sequence_length += sum(sequences_lengths)\n",
    "\n",
    "    return full_val_loss / (overall_sequence_length * 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:23:12.210378Z",
     "start_time": "2018-11-27T12:22:58.040622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.122862009737202e-06"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:16:15.631943Z",
     "start_time": "2018-11-26T16:16:15.434830Z"
    }
   },
   "outputs": [],
   "source": [
    "clip = 1.0\n",
    "best_val_loss = float(\"inf\")\n",
    "def get_triangular_lr(lr_low, lr_high, mini_batches):\n",
    "    iterations = mini_batches\n",
    "    lr_mid = lr_high/7 + lr_low\n",
    "    up = np.linspace(lr_low, lr_high, int(round(iterations*0.35)))\n",
    "    down = np.linspace(lr_high, lr_mid, int(round(iterations*0.35)))\n",
    "    floor = np.linspace(lr_mid, lr_low, int(round(iterations*0.30)))\n",
    "    return np.hstack([up, down[1:], floor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:16:18.949227Z",
     "start_time": "2018-11-26T16:16:18.930281Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, lrs_triangular, epochs_number=2, wd=0.0, best_val_loss=float(\"inf\")):\n",
    "    loss_list = []\n",
    "    val_list =[]\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=lrs_triangular[0], weight_decay=wd)\n",
    "    for epoch_number in range(epochs_number):\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "        for lr, batch in zip(lrs_triangular, trainset_loader):\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "            loss = criterion(logits, output_sequences_batch_var)\n",
    "            loss_list.append(loss.item())\n",
    "            epoch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n",
    "        print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n",
    "\n",
    "        current_val_loss = validate(model)\n",
    "        print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n",
    "        print('')\n",
    "\n",
    "        val_list.append(current_val_loss)\n",
    "\n",
    "        if current_val_loss < best_val_loss:\n",
    "\n",
    "            torch.save(model.state_dict(), 'best.pth')\n",
    "            best_val_loss = current_val_loss\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f0790f9f950>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:19:05.465667Z",
     "start_time": "2018-11-26T16:16:20.312589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: Epoch: 0 : 0.9615547561645508\n",
      "Validation Loss: Epoch: 0 : 1.0712490980193408e-06\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.37935748100280764\n",
      "Validation Loss: Epoch: 1 : 1.0341778857955328e-06\n",
      "\n",
      "Training Loss: Epoch: 0 : 0.2866771030426025\n",
      "Validation Loss: Epoch: 0 : 7.449739865769681e-07\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.23830525934696198\n",
      "Validation Loss: Epoch: 1 : 5.897248096715474e-07\n",
      "\n",
      "Training Loss: Epoch: 0 : 0.23312038719654082\n",
      "Validation Loss: Epoch: 0 : 5.540749770576611e-07\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.21500825583934785\n",
      "Validation Loss: Epoch: 1 : 4.723249277424298e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
    "rnn = rnn.cuda()\n",
    "lrs_triangular = get_triangular_lr(1e-2, 1e-2*3.5, len(trainset_loader))\n",
    "best_val_loss = train_model(rnn, lrs_triangular)\n",
    "lrs_triangular = get_triangular_lr(1e-3, 1e-2, len(trainset_loader))\n",
    "best_val_loss = train_model(rnn, lrs_triangular, epochs_number=2, wd=1e-4, best_val_loss=best_val_loss)\n",
    "lrs_triangular = get_triangular_lr(1e-4, 1e-2, len(trainset_loader))\n",
    "best_val_loss = train_model(rnn, lrs_triangular, epochs_number=2, wd=1e-4*5, best_val_loss=best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:15:52.123518Z",
     "start_time": "2018-11-26T16:11:03.940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.load_state_dict(torch.load('best.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:11.202962Z",
     "start_time": "2018-11-26T16:25:11.189993Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_from_piano_rnn(rnn, sample_length=4, temperature=1, starting_sequence=None):\n",
    "\n",
    "    if starting_sequence is None:\n",
    "                \n",
    "        current_sequence_input = torch.zeros(1, 1, 88)\n",
    "        current_sequence_input[0, 0, 40] = 1\n",
    "        current_sequence_input[0, 0, 50] = 0\n",
    "        current_sequence_input[0, 0, 56] = 0\n",
    "        current_sequence_input = Variable(current_sequence_input.cuda())\n",
    "    else:\n",
    "        current_sequence_input = starting_sequence\n",
    "        \n",
    "    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(sample_length):\n",
    "\n",
    "        output, hidden = rnn(current_sequence_input, [1], hidden)\n",
    "\n",
    "        probabilities = nn.functional.softmax(output.div(temperature), dim=1)\n",
    "\n",
    "        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        current_sequence_input = Variable(current_sequence_input.float())\n",
    "\n",
    "        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n",
    "\n",
    "    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().numpy()\n",
    "    \n",
    "    return sampled_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:36.632928Z",
     "start_time": "2018-11-26T16:25:34.966547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sample_from_piano_rnn(rnn, sample_length=200, temperature=0.7,starting_sequence=None).transpose()\n",
    "io.imshow(sample)\n",
    "midiwrite('sample.mid', sample.transpose(), dt=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:30:38.850609Z",
     "start_time": "2018-11-26T16:30:38.843627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sample.mid' target='_blank'>sample.mid</a><br>"
      ],
      "text/plain": [
       "/home/jovyan/Music-Generation/notebooks/sample.mid"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('sample.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
