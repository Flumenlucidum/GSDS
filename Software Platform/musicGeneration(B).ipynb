{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:43.948987Z",
     "start_time": "2018-11-27T12:20:30.225783Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('../midi')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:52.800756Z",
     "start_time": "2018-11-27T12:20:43.965495Z"
    }
   },
   "outputs": [],
   "source": [
    "from midi_utils import midiread, midiwrite\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.io as io\n",
    "from IPython.display import FileLink\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:52.867674Z",
     "start_time": "2018-11-27T12:20:52.819795Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "def midi_filename_to_piano_roll(midi_filename):\n",
    "    \n",
    "    midi_data = midiread(midi_filename, dt=0.3)\n",
    "    \n",
    "    piano_roll = midi_data.piano_roll.transpose()\n",
    "    \n",
    "    # Pressed notes are replaced by 1\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "    \n",
    "    return piano_roll\n",
    "\n",
    "\n",
    "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
    "        \n",
    "    original_piano_roll_length = piano_roll.shape[1]\n",
    "    \n",
    "    padded_piano_roll = np.zeros((88, max_length))\n",
    "    padded_piano_roll[:] = pad_value\n",
    "    \n",
    "    padded_piano_roll[:, -original_piano_roll_length:] = piano_roll\n",
    "\n",
    "    return padded_piano_roll\n",
    "\n",
    "\n",
    "class NotesGenerationDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
    "        \n",
    "        self.midi_folder_path = midi_folder_path\n",
    "        \n",
    "        midi_filenames = os.listdir(midi_folder_path)\n",
    "        \n",
    "        self.longest_sequence_length = longest_sequence_length\n",
    "        \n",
    "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n",
    "        \n",
    "        self.midi_full_filenames = list(midi_full_filenames)\n",
    "        \n",
    "        if longest_sequence_length is None:\n",
    "            \n",
    "            self.update_the_max_length()\n",
    "    \n",
    "    \n",
    "    def update_the_max_length(self):\n",
    "        \n",
    "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],self.midi_full_filenames)\n",
    "        \n",
    "        max_length = max(sequences_lengths)\n",
    "        \n",
    "        self.longest_sequence_length = max_length\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.midi_full_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        midi_full_filename = self.midi_full_filenames[index]\n",
    "        \n",
    "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
    "        \n",
    "        # Shifting by one time step\n",
    "        sequence_length = piano_roll.shape[1] - 1\n",
    "        \n",
    "        # Shifting by one time step\n",
    "        input_sequence = piano_roll[:, :-1]\n",
    "        ground_truth_sequence = piano_roll[:, 1:]\n",
    "                \n",
    "        # padding sequence so that all of them have the same length\n",
    "        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n",
    "        \n",
    "        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,max_length=self.longest_sequence_length,pad_value=-100)\n",
    "                \n",
    "        input_sequence_padded = input_sequence_padded.transpose()\n",
    "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
    "        \n",
    "        return (torch.FloatTensor(input_sequence_padded),torch.LongTensor(ground_truth_sequence_padded),torch.LongTensor([sequence_length]) )\n",
    "\n",
    "    \n",
    "def post_process_sequence_batch(batch_tuple):\n",
    "    \n",
    "    input_sequences, output_sequences, lengths = batch_tuple\n",
    "    \n",
    "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
    "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
    "    splitted_lengths_batch = lengths.split(split_size=1)\n",
    "\n",
    "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
    "                               splitted_output_sequence_batch,\n",
    "                               splitted_lengths_batch)\n",
    "\n",
    "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
    "                                         key=lambda p: int(p[2]),\n",
    "                                         reverse=True)\n",
    "\n",
    "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
    "\n",
    "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
    "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
    "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
    "    \n",
    "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
    "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
    "    \n",
    "    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
    "    \n",
    "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
    "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
    "    \n",
    "    return input_sequence_batch_transposed, output_sequence_batch_sorted, list(lengths_batch_sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('500song'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob(os.path.join('./musictraining/ABBA', '*.*')):\n",
    "    shutil.copy(filename, './500song')\n",
    "\n",
    "for filename in glob.glob(os.path.join('./musictraining/Queen', '*.*')):\n",
    "    shutil.copy(filename, './500song')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob(os.path.join('./musictraining/U2', '*.*')):\n",
    "    shutil.copy(filename, './500song')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "amidi_folder_path = './500song'\n",
    "        \n",
    "amidi_filenames = os.listdir(amidi_folder_path)\n",
    "amidi_full_filenames =map(lambda filename: os.path.join(amidi_folder_path, filename), amidi_filenames)\n",
    "\n",
    "for filename in list(amidi_full_filenames):\n",
    "    \n",
    "    \n",
    "    try: sequences_lengths = midi_filename_to_piano_roll(filename).shape[1]\n",
    "    \n",
    "    except:\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)\n",
    "        elif os.path.isdir(filename):\n",
    "            shutil.rmtree(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob(os.path.join('./musictraining/Bob Dylan', '*.*')):\n",
    "    shutil.copy(filename, './500song')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob(os.path.join('./musictraining/Bobby Brown', '*.*')):\n",
    "    shutil.copy(filename, './500song')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.glob(os.path.join('./musictraining/Elvin Bishop', '*.*')):\n",
    "    shutil.copy(filename, './500song')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:07.678124Z",
     "start_time": "2018-11-27T12:20:56.931002Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = NotesGenerationDataset('./500song', longest_sequence_length=None)\n",
    "\n",
    "trainset_loader = data.DataLoader(trainset, batch_size=8,shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:08.232332Z",
     "start_time": "2018-11-27T12:21:07.693745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2873, 88])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = next(iter(trainset_loader))\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:11.258476Z",
     "start_time": "2018-11-27T12:21:08.259258Z"
    }
   },
   "outputs": [],
   "source": [
    "valset = NotesGenerationDataset('./500song', longest_sequence_length=None)\n",
    "\n",
    "valset_loader = data.DataLoader(valset, batch_size=8, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:11.406325Z",
     "start_time": "2018-11-27T12:21:11.278687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2873, 88])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = next(iter(valset_loader))\n",
    "X_val[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:33.314323Z",
     "start_time": "2018-11-27T12:22:33.291386Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, n_layers=2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.notes_encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_sequences, input_sequences_lengths, hidden=None):\n",
    "        batch_size = input_sequences.shape[1]\n",
    "\n",
    "        notes_encoded = self.notes_encoder(input_sequences)\n",
    "        \n",
    "        notes_encoded_rolled = notes_encoded.permute(1,2,0).contiguous()\n",
    "        notes_encoded_norm = self.bn(notes_encoded_rolled)\n",
    "        \n",
    "        notes_encoded_norm_drop = nn.Dropout(0.25)(notes_encoded_norm)\n",
    "        notes_encoded_complete = notes_encoded_norm_drop.permute(2,0,1)\n",
    "        \n",
    "        # Here we run rnns only on non-padded regions of the batch\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(notes_encoded_complete, input_sequences_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        # Here we unpack sequence(back to padded)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        \n",
    "        outputs_norm = self.bn(outputs.permute(1,2,0).contiguous())\n",
    "        outputs_drop = nn.Dropout(0.1)(outputs_norm)\n",
    "        logits = self.logits_fc(outputs_drop.permute(2,0,1))\n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        \n",
    "        neg_logits = (1 - logits)\n",
    "        \n",
    "        # Since the BCE loss doesn't support masking,crossentropy is used\n",
    "        binary_logits = torch.stack((logits, neg_logits), dim=3).contiguous()\n",
    "        logits_flatten = binary_logits.view(-1, 2)\n",
    "        return logits_flatten, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:57.954631Z",
     "start_time": "2018-11-27T12:22:36.786295Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RNN(input_size=88, hidden_size=512, num_classes=88).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion_val = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:58.002722Z",
     "start_time": "2018-11-27T12:22:57.987764Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "    model.eval()\n",
    "    full_val_loss = 0.0\n",
    "    overall_sequence_length = 0.0\n",
    "\n",
    "    for batch in valset_loader:\n",
    "\n",
    "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "        logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "        loss = criterion_val(logits, output_sequences_batch_var)\n",
    "\n",
    "        full_val_loss += loss.item()\n",
    "        overall_sequence_length += sum(sequences_lengths)\n",
    "\n",
    "    return full_val_loss / (overall_sequence_length * 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:23:12.210378Z",
     "start_time": "2018-11-27T12:22:58.040622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2026733674594427e-06"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:16:15.631943Z",
     "start_time": "2018-11-26T16:16:15.434830Z"
    }
   },
   "outputs": [],
   "source": [
    "clip = 1.0\n",
    "best_val_loss = float(\"inf\")\n",
    "def get_triangular_lr(lr_low, lr_high, mini_batches):\n",
    "    iterations = mini_batches\n",
    "    lr_mid = lr_high/7 + lr_low\n",
    "    up = np.linspace(lr_low, lr_high, int(round(iterations*0.35)))\n",
    "    down = np.linspace(lr_high, lr_mid, int(round(iterations*0.35)))\n",
    "    floor = np.linspace(lr_mid, lr_low, int(round(iterations*0.30)))\n",
    "    return np.hstack([up, down[1:], floor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:16:18.949227Z",
     "start_time": "2018-11-26T16:16:18.930281Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, lrs_triangular, epochs_number=2, wd=0.0, best_val_loss=float(\"inf\")):\n",
    "    loss_list = []\n",
    "    val_list =[]\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=lrs_triangular[0], weight_decay=wd)\n",
    "    for epoch_number in range(epochs_number):\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "        for lr, batch in zip(lrs_triangular, trainset_loader):\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "            loss = criterion(logits, output_sequences_batch_var)\n",
    "            loss_list.append(loss.item())\n",
    "            epoch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n",
    "        print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n",
    "\n",
    "        current_val_loss = validate(model)\n",
    "        print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n",
    "        print('')\n",
    "\n",
    "        val_list.append(current_val_loss)\n",
    "\n",
    "        if current_val_loss < best_val_loss:\n",
    "\n",
    "            torch.save(model.state_dict(), 'best.pth')\n",
    "            best_val_loss = current_val_loss\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f12539b8310>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:19:05.465667Z",
     "start_time": "2018-11-26T16:16:20.312589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: Epoch: 0 : 0.4745335377031757\n",
      "Validation Loss: Epoch: 0 : 4.813035668972101e-07\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.234599651107865\n",
      "Validation Loss: Epoch: 1 : 3.675561447094372e-07\n",
      "\n",
      "Training Loss: Epoch: 0 : 0.19018698003022902\n",
      "Validation Loss: Epoch: 0 : 3.0784554559855126e-07\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.1718818773665736\n",
      "Validation Loss: Epoch: 1 : 3.210152634792753e-07\n",
      "\n",
      "Training Loss: Epoch: 0 : 0.1700876213369831\n",
      "Validation Loss: Epoch: 0 : 3.3490907633081196e-07\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.1703051660330065\n",
      "Validation Loss: Epoch: 1 : 3.12241586973815e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
    "rnn = rnn.cuda()\n",
    "lrs_triangular = get_triangular_lr(1e-2, 1e-2*3.5, len(trainset_loader))\n",
    "best_val_loss = train_model(rnn, lrs_triangular)\n",
    "lrs_triangular = get_triangular_lr(1e-3, 1e-2, len(trainset_loader))\n",
    "best_val_loss = train_model(rnn, lrs_triangular, epochs_number=2, wd=1e-4, best_val_loss=best_val_loss)\n",
    "lrs_triangular = get_triangular_lr(1e-4, 1e-2, len(trainset_loader))\n",
    "best_val_loss = train_model(rnn, lrs_triangular, epochs_number=2, wd=1e-4*5, best_val_loss=best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:15:52.123518Z",
     "start_time": "2018-11-26T16:11:03.940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.load_state_dict(torch.load('best.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:11.202962Z",
     "start_time": "2018-11-26T16:25:11.189993Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_from_piano_rnn(rnn, sample_length=4, temperature=1, starting_sequence=None):\n",
    "\n",
    "    if starting_sequence is None:\n",
    "                \n",
    "        current_sequence_input = torch.zeros(1, 1, 88)\n",
    "        current_sequence_input[0, 0, 40] = 1\n",
    "        current_sequence_input[0, 0, 50] = 0\n",
    "        current_sequence_input[0, 0, 56] = 0\n",
    "        current_sequence_input = Variable(current_sequence_input.cuda())\n",
    "    else:\n",
    "        current_sequence_input = starting_sequence\n",
    "        \n",
    "    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(sample_length):\n",
    "\n",
    "        output, hidden = rnn(current_sequence_input, [1], hidden)\n",
    "\n",
    "        probabilities = nn.functional.softmax(output.div(temperature), dim=1)\n",
    "\n",
    "        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        current_sequence_input = Variable(current_sequence_input.float())\n",
    "\n",
    "        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n",
    "\n",
    "    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().numpy()\n",
    "    \n",
    "    return sampled_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:36.632928Z",
     "start_time": "2018-11-26T16:25:34.966547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sample_from_piano_rnn(rnn, sample_length=200, temperature=0.7,starting_sequence=None).transpose()\n",
    "io.imshow(sample)\n",
    "midiwrite('sample.mid', sample.transpose(), dt=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:30:38.850609Z",
     "start_time": "2018-11-26T16:30:38.843627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sample.mid' target='_blank'>sample.mid</a><br>"
      ],
      "text/plain": [
       "/home/jovyan/Music-Generation/notebooks/sample.mid"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('sample.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
