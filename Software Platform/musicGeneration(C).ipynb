{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:43.948987Z",
     "start_time": "2018-11-27T12:20:30.225783Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('../midi')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:52.800756Z",
     "start_time": "2018-11-27T12:20:43.965495Z"
    }
   },
   "outputs": [],
   "source": [
    "from midi_utils import midiread, midiwrite\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.io as io\n",
    "from IPython.display import FileLink\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:20:52.867674Z",
     "start_time": "2018-11-27T12:20:52.819795Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "def midi_filename_to_piano_roll(midi_filename):\n",
    "    \n",
    "    midi_data = midiread(midi_filename, dt=0.3)\n",
    "    \n",
    "    piano_roll = midi_data.piano_roll.transpose()\n",
    "    \n",
    "    # Pressed notes are replaced by 1\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "    \n",
    "    return piano_roll\n",
    "\n",
    "\n",
    "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
    "        \n",
    "    original_piano_roll_length = piano_roll.shape[1]\n",
    "    \n",
    "    padded_piano_roll = np.zeros((88, max_length))\n",
    "    padded_piano_roll[:] = pad_value\n",
    "    \n",
    "    padded_piano_roll[:, -original_piano_roll_length:] = piano_roll\n",
    "\n",
    "    return padded_piano_roll\n",
    "\n",
    "\n",
    "class NotesGenerationDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
    "        \n",
    "        self.midi_folder_path = midi_folder_path\n",
    "        \n",
    "        midi_filenames = os.listdir(midi_folder_path)\n",
    "        \n",
    "        self.longest_sequence_length = longest_sequence_length\n",
    "        \n",
    "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),midi_filenames)\n",
    "        \n",
    "        self.midi_full_filenames = list(midi_full_filenames)\n",
    "        \n",
    "        if longest_sequence_length is None:\n",
    "            \n",
    "            self.update_the_max_length()\n",
    "    \n",
    "    \n",
    "    def update_the_max_length(self):\n",
    "        \n",
    "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],self.midi_full_filenames)\n",
    "        \n",
    "        max_length = max(sequences_lengths)\n",
    "        \n",
    "        self.longest_sequence_length = max_length\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.midi_full_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        midi_full_filename = self.midi_full_filenames[index]\n",
    "        \n",
    "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
    "        \n",
    "        # Shifting by one time step\n",
    "        sequence_length = piano_roll.shape[1] - 1\n",
    "        \n",
    "        # Shifting by one time step\n",
    "        input_sequence = piano_roll[:, :-1]\n",
    "        ground_truth_sequence = piano_roll[:, 1:]\n",
    "                \n",
    "        # padding sequence so that all of them have the same length\n",
    "        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n",
    "        \n",
    "        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,max_length=self.longest_sequence_length,pad_value=-100)\n",
    "                \n",
    "        input_sequence_padded = input_sequence_padded.transpose()\n",
    "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
    "        \n",
    "        return (torch.FloatTensor(input_sequence_padded),torch.LongTensor(ground_truth_sequence_padded),torch.LongTensor([sequence_length]) )\n",
    "\n",
    "    \n",
    "def post_process_sequence_batch(batch_tuple):\n",
    "    \n",
    "    input_sequences, output_sequences, lengths = batch_tuple\n",
    "    \n",
    "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
    "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
    "    splitted_lengths_batch = lengths.split(split_size=1)\n",
    "\n",
    "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
    "                               splitted_output_sequence_batch,\n",
    "                               splitted_lengths_batch)\n",
    "\n",
    "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
    "                                         key=lambda p: int(p[2]),\n",
    "                                         reverse=True)\n",
    "\n",
    "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
    "\n",
    "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
    "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
    "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
    "    \n",
    "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
    "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, -lengths_batch_sorted[0, 0]:, :]\n",
    "    \n",
    "    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
    "    \n",
    "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
    "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
    "    \n",
    "    return input_sequence_batch_transposed, output_sequence_batch_sorted, list(lengths_batch_sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('allsong'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in os.listdir('./musictraining'):\n",
    "    \n",
    "    for filename in glob.glob(os.path.join('./musictraining/'+artist, '*.*')):\n",
    "        shutil.copy(filename, './allsong')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('allsongrandom'))\n",
    "filenames = random.sample(os.listdir('./allsong'), 500)\n",
    "for fname in filenames:\n",
    "\n",
    "    srcpath = os.path.join('./allsong', fname)\n",
    "    if os.path.isfile(srcpath):\n",
    "        shutil.copy(srcpath, './allsongrandom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove files with errors\n",
    "midi_folder_path = './allsongrandom'\n",
    "        \n",
    "midi_filenames = os.listdir(midi_folder_path)\n",
    "midi_full_filenames =map(lambda filename: os.path.join(midi_folder_path, filename), midi_filenames)\n",
    "\n",
    "for filename in list(midi_full_filenames):\n",
    "    \n",
    "    \n",
    "    try: sequences_lengths = midi_filename_to_piano_roll(filename).shape[1]\n",
    "    \n",
    "    except:\n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)\n",
    "        elif os.path.isdir(filename):\n",
    "            shutil.rmtree(filename)\n",
    "            \n",
    "while (len(os.listdir('./allsongrandom'))!=500):\n",
    "    \n",
    "    moresong=500-len(os.listdir('./allsongrandom'))\n",
    "    filenames = random.sample(os.listdir('./allsong'), moresong)\n",
    "    for fname in filenames:\n",
    "\n",
    "        srcpath = os.path.join('./allsong', fname)\n",
    "        if os.path.isfile(srcpath):\n",
    "            shutil.copy(srcpath, './allsongrandom')\n",
    "    #remove files with errors\n",
    "    midi_folder_path = './allsongrandom'\n",
    "\n",
    "    midi_filenames = os.listdir(midi_folder_path)\n",
    "    midi_full_filenames =map(lambda filename: os.path.join(midi_folder_path, filename), midi_filenames)\n",
    "\n",
    "    for filename in list(midi_full_filenames):\n",
    "\n",
    "\n",
    "        try: sequences_lengths = midi_filename_to_piano_roll(filename).shape[1]\n",
    "\n",
    "        except:\n",
    "            if os.path.isfile(filename):\n",
    "                os.remove(filename)\n",
    "            elif os.path.isdir(filename):\n",
    "                shutil.rmtree(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:07.678124Z",
     "start_time": "2018-11-27T12:20:56.931002Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = NotesGenerationDataset('./allsongrandom', longest_sequence_length=None)\n",
    "\n",
    "trainset_loader = data.DataLoader(trainset, batch_size=8,shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:08.232332Z",
     "start_time": "2018-11-27T12:21:07.693745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2335, 88])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = next(iter(trainset_loader))\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:11.258476Z",
     "start_time": "2018-11-27T12:21:08.259258Z"
    }
   },
   "outputs": [],
   "source": [
    "valset = NotesGenerationDataset('./allsongrandom', longest_sequence_length=None)\n",
    "\n",
    "valset_loader = data.DataLoader(valset, batch_size=8, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:21:11.406325Z",
     "start_time": "2018-11-27T12:21:11.278687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2335, 88])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = next(iter(valset_loader))\n",
    "X_val[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:33.314323Z",
     "start_time": "2018-11-27T12:22:33.291386Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, n_layers=2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.notes_encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_sequences, input_sequences_lengths, hidden=None):\n",
    "        batch_size = input_sequences.shape[1]\n",
    "\n",
    "        notes_encoded = self.notes_encoder(input_sequences)\n",
    "        \n",
    "        notes_encoded_rolled = notes_encoded.permute(1,2,0).contiguous()\n",
    "        notes_encoded_norm = self.bn(notes_encoded_rolled)\n",
    "        \n",
    "        notes_encoded_norm_drop = nn.Dropout(0.25)(notes_encoded_norm)\n",
    "        notes_encoded_complete = notes_encoded_norm_drop.permute(2,0,1)\n",
    "        \n",
    "        # Here we run rnns only on non-padded regions of the batch\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(notes_encoded_complete, input_sequences_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        # Here we unpack sequence(back to padded)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        \n",
    "        outputs_norm = self.bn(outputs.permute(1,2,0).contiguous())\n",
    "        outputs_drop = nn.Dropout(0.1)(outputs_norm)\n",
    "        logits = self.logits_fc(outputs_drop.permute(2,0,1))\n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        \n",
    "        neg_logits = (1 - logits)\n",
    "        \n",
    "        # Since the BCE loss doesn't support masking,crossentropy is used\n",
    "        binary_logits = torch.stack((logits, neg_logits), dim=3).contiguous()\n",
    "        logits_flatten = binary_logits.view(-1, 2)\n",
    "        return logits_flatten, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:57.954631Z",
     "start_time": "2018-11-27T12:22:36.786295Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RNN(input_size=88, hidden_size=512, num_classes=88).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion_val = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:22:58.002722Z",
     "start_time": "2018-11-27T12:22:57.987764Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "    model.eval()\n",
    "    full_val_loss = 0.0\n",
    "    overall_sequence_length = 0.0\n",
    "\n",
    "    for batch in valset_loader:\n",
    "\n",
    "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "        logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "        loss = criterion_val(logits, output_sequences_batch_var)\n",
    "\n",
    "        full_val_loss += loss.item()\n",
    "        overall_sequence_length += sum(sequences_lengths)\n",
    "\n",
    "    return full_val_loss / (overall_sequence_length * 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T12:23:12.210378Z",
     "start_time": "2018-11-27T12:22:58.040622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.322346888434904e-06"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:16:15.631943Z",
     "start_time": "2018-11-26T16:16:15.434830Z"
    }
   },
   "outputs": [],
   "source": [
    "clip = 1.0\n",
    "best_val_loss = float(\"inf\")\n",
    "def get_triangular_lr(lr_low, lr_high, mini_batches):\n",
    "    iterations = mini_batches\n",
    "    lr_mid = lr_high/7 + lr_low\n",
    "    up = np.linspace(lr_low, lr_high, int(round(iterations*0.35)))\n",
    "    down = np.linspace(lr_high, lr_mid, int(round(iterations*0.35)))\n",
    "    floor = np.linspace(lr_mid, lr_low, int(round(iterations*0.30)))\n",
    "    return np.hstack([up, down[1:], floor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:16:18.949227Z",
     "start_time": "2018-11-26T16:16:18.930281Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, lrs_triangular, epochs_number=2, wd=0.0, best_val_loss=float(\"inf\")):\n",
    "    loss_list = []\n",
    "    val_list =[]\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=lrs_triangular[0], weight_decay=wd)\n",
    "    for epoch_number in range(epochs_number):\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "        for lr, batch in zip(lrs_triangular, trainset_loader):\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, _ = model(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "            loss = criterion(logits, output_sequences_batch_var)\n",
    "            loss_list.append(loss.item())\n",
    "            epoch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n",
    "        print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n",
    "\n",
    "        current_val_loss = validate(model)\n",
    "        print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n",
    "        print('')\n",
    "\n",
    "        val_list.append(current_val_loss)\n",
    "\n",
    "        if current_val_loss < best_val_loss:\n",
    "\n",
    "            torch.save(model.state_dict(), 'best.pth')\n",
    "            best_val_loss = current_val_loss\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fc732880890>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:19:05.465667Z",
     "start_time": "2018-11-26T16:16:20.312589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: Epoch: 0 : 0.5190308401661534\n",
      "Validation Loss: Epoch: 0 : 5.75750243760698e-07\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.23875880289462306\n",
      "Validation Loss: Epoch: 1 : 4.0736353833179656e-07\n",
      "\n",
      "Training Loss: Epoch: 0 : 0.20050431115012016\n",
      "Validation Loss: Epoch: 0 : 3.552353740501638e-07\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.18879321385775844\n",
      "Validation Loss: Epoch: 1 : 3.351478209734587e-07\n",
      "\n",
      "Training Loss: Epoch: 0 : 0.19038208838432066\n",
      "Validation Loss: Epoch: 0 : 3.466283594499363e-07\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.18129283358012477\n",
      "Validation Loss: Epoch: 1 : 3.5070963058400304e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
    "rnn = rnn.cuda()\n",
    "lrs_triangular = get_triangular_lr(1e-2, 1e-2*3.5, len(trainset_loader))\n",
    "best_val_loss = train_model(rnn, lrs_triangular)\n",
    "lrs_triangular = get_triangular_lr(1e-3, 1e-2, len(trainset_loader))\n",
    "best_val_loss = train_model(rnn, lrs_triangular, epochs_number=2, wd=1e-4, best_val_loss=best_val_loss)\n",
    "lrs_triangular = get_triangular_lr(1e-4, 1e-2, len(trainset_loader))\n",
    "best_val_loss = train_model(rnn, lrs_triangular, epochs_number=2, wd=1e-4*5, best_val_loss=best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:15:52.123518Z",
     "start_time": "2018-11-26T16:11:03.940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.load_state_dict(torch.load('best.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:11.202962Z",
     "start_time": "2018-11-26T16:25:11.189993Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_from_piano_rnn(rnn, sample_length=4, temperature=1, starting_sequence=None):\n",
    "\n",
    "    if starting_sequence is None:\n",
    "                \n",
    "        current_sequence_input = torch.zeros(1, 1, 88)\n",
    "        current_sequence_input[0, 0, 40] = 1\n",
    "        current_sequence_input[0, 0, 50] = 0\n",
    "        current_sequence_input[0, 0, 56] = 0\n",
    "        current_sequence_input = Variable(current_sequence_input.cuda())\n",
    "    else:\n",
    "        current_sequence_input = starting_sequence\n",
    "        \n",
    "    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(sample_length):\n",
    "\n",
    "        output, hidden = rnn(current_sequence_input, [1], hidden)\n",
    "\n",
    "        probabilities = nn.functional.softmax(output.div(temperature), dim=1)\n",
    "\n",
    "        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        current_sequence_input = Variable(current_sequence_input.float())\n",
    "\n",
    "        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n",
    "\n",
    "    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().numpy()\n",
    "    \n",
    "    return sampled_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:25:36.632928Z",
     "start_time": "2018-11-26T16:25:34.966547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sample_from_piano_rnn(rnn, sample_length=200, temperature=0.7,starting_sequence=None).transpose()\n",
    "io.imshow(sample)\n",
    "midiwrite('sample.mid', sample.transpose(), dt=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:30:38.850609Z",
     "start_time": "2018-11-26T16:30:38.843627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sample.mid' target='_blank'>sample.mid</a><br>"
      ],
      "text/plain": [
       "/home/jovyan/Music-Generation/notebooks/sample.mid"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('sample.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
