{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The official website of the MNIST dataset is Yann LeCunâ€™s website. From this website, you can download the Python source code for automatically downloading and installing the MNIST dataset. (using input_data.py is attached in Assigment's folder or using \n",
    "from tensorflow.examples.tutorials.mnist import input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "# Import data\n",
    "import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#SoftMax function implementation\n",
    "\n",
    "# Create the model y = W*x + b.  :\n",
    "# image_size = 28\n",
    "# num_labels = 10\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "x = \n",
    "W = \n",
    "b = \n",
    "y = \n",
    "##############################################################################\n",
    "#                          END YOUR CODE                                     #\n",
    "##############################################################################\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "# Train\n",
    "tf.initialize_all_variables().run()\n",
    "for i in range(1000):\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "    batch_xs, batch_ys = \n",
    "    train_step.run({x: batch_xs, y_: batch_ys})\n",
    "##############################################################################\n",
    "#                          END YOUR CODE                                     #\n",
    "##############################################################################\n",
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy is \", accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning-19] *",
   "language": "python",
   "name": "conda-env-deep-learning-19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
